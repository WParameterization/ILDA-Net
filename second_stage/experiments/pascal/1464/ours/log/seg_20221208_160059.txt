[2022-12-08 16:01:00,817][    INFO] {'criterion': {'kwargs': {'use_weight': False}, 'type': 'CELoss'},
 'dataset': {'batch_size': 2,
             'ignore_label': 255,
             'mean': [123.675, 116.28, 103.53],
             'n_sup': 195,
             'noise_std': 0.1,
             'std': [58.395, 57.12, 57.375],
             'train': {'GaussianBlur': False,
                       'crop': {'size': [256, 256], 'type': 'rand'},
                       'data_list': '../../../../data/splits/pascal/1464/labeled.txt',
                       'data_root': '../../../../data/VOC2012',
                       'flip': True,
                       'rand_resize': [0.5, 2.0]},
             'type': 'pascal_semi',
             'val': {'crop': {'size': [256, 256], 'type': 'center'},
                     'data_list': '../../../../data/splits/pascal/val.txt',
                     'data_root': '../../../../data/VOC2012'},
             'workers': 1},
 'exp_path': '',
 'net': {'bo': {'type': 'u2pl.models.model_helper.Bottleneck'},
         'decoder': {'type': 'u2pl.models.model_helper.Decoder'},
         'ema_decay': 0.99,
         'encoder': {'type': 'u2pl.models.model_helper.Encoder'},
         'fc_inch': '121,',
         'filters': '32,',
         'in_channels': '3,',
         'n_class': '9,',
         'num_classes': 9,
         'sync_bn': True},
 'save_path': 'checkpoints101_rgb',
 'saver': {'pretrain': '', 'snapshot_dir': 'checkpoints101_rgb'},
 'trainer': {'contrastive': {'current_class_negative_threshold': 1,
                             'current_class_threshold': 0.3,
                             'high_rank': 20,
                             'low_entropy_threshold': 20,
                             'low_rank': 3,
                             'negative_high_entropy': True,
                             'num_negatives': 101,
                             'num_queries': 256,
                             'temperature': 0.5,
                             'unsupervised_entropy_ignore': 80},
             'epochs': 80,
             'eval_on': True,
             'lr_scheduler': {'kwargs': {'power': 0.9}, 'mode': 'poly'},
             'optimizer': {'kwargs': {'lr': 0.001,
                                      'momentum': 0.9,
                                      'weight_decay': 0.0001},
                           'type': 'SGD'},
             'unsupervised': {'TTA': False,
                              'apply_aug': 'cutmix',
                              'drop_percent': 80}}}
set random seed to 2
[2022-12-08 16:01:03,642][    INFO] # samples: 202
[2022-12-08 16:01:03,646][    INFO] # samples: 1418
[2022-12-08 16:01:03,648][    INFO] # samples: 180
[2022-12-08 16:01:03,648][    INFO] Get loader Done...
[2022-12-08 16:01:03,858][    INFO] The kwargs for lr scheduler: 0.9
torch.Size([2, 512, 16, 16]) torch.Size([2, 32, 256, 256]) tttttttttttttt
Traceback (most recent call last):
  File "../../../../train_semi1.py", line 480, in <module>
    main()
  File "../../../../train_semi1.py", line 147, in main
    train( model, model_teacher, optimizer,lr_scheduler,sup_loss_fn, train_loader_sup,train_loader_unsup,epoch,tb_logger,logger,memobank,queue_ptrlis,queue_size,)
  File "../../../../train_semi1.py", line 210, in train
    outs = model(image_l)#student和teacher模型的应该是一样的，不然不能进行ema
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 705, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/lenovo/新加卷1/U2PL/u2pl/models/model_helper.py", line 59, in forward
    output = self.decoder(output_bottleneck, skip)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/lenovo/新加卷1/U2PL/u2pl/models/model_helper.py", line 171, in forward
    output = layer(output)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [9, 32, 1, 1], expected input[2, 256, 32, 32] to have 32 channels, but got 256 channels instead
Traceback (most recent call last):
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/lenovo/anaconda3/envs/ronghe/lib/python3.6/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/lenovo/anaconda3/envs/ronghe/bin/python', '-u', '../../../../train_semi1.py', '--local_rank=0', '--config=config.yaml', '--seed', '2', '--port', '1254']' returned non-zero exit status 1.
Killing subprocess 23838
