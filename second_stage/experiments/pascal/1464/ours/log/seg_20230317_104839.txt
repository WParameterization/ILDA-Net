Using TensorFlow backend.
[2023-03-17 10:48:46,222][    INFO] {'criterion': {'kwargs': {'use_weight': False}, 'type': 'CELoss'},
 'dataset': {'batch_size': 8,
             'ignore_label': 255,
             'mean': [123.675, 116.28, 103.53],
             'n_sup': 195,
             'noise_std': 0.1,
             'std': [58.395, 57.12, 57.375],
             'train': {'GaussianBlur': False,
                       'crop': {'size': [256, 256], 'type': 'rand'},
                       'data_list': '../../../../data/splits/pascal/1464/labeled.txt',
                       'data_root': '../../../../data/VOC2012',
                       'flip': True,
                       'rand_resize': [0.5, 2.0]},
             'type': 'pascal_semi',
             'val': {'crop': {'size': [256, 256], 'type': 'center'},
                     'data_list': '../../../../data/splits/pascal/val.txt',
                     'data_root': '../../../../data/VOC2012'},
             'workers': 1},
 'exp_path': '',
 'net': {'bo': {'type': 'u2pl.models.model_helper.Bottleneck'},
         'decoder': {'type': 'u2pl.models.model_helper.Decoder'},
         'ema_decay': 0.99,
         'encoder': {'type': 'u2pl.models.model_helper.Encoder'},
         'fc_inch': '121,',
         'filters': '32,',
         'in_channels': '3,',
         'n_class': '9,',
         'num_classes': 9,
         'sync_bn': True},
 'save_path': 'checkpoints101_rgb',
 'saver': {'pretrain': '', 'snapshot_dir': 'checkpoints101_rgb'},
 'trainer': {'contrastive': {'current_class_negative_threshold': 1,
                             'current_class_threshold': 0.3,
                             'high_rank': 20,
                             'low_entropy_threshold': 20,
                             'low_rank': 3,
                             'negative_high_entropy': True,
                             'num_negatives': 101,
                             'num_queries': 256,
                             'temperature': 0.5,
                             'unsupervised_entropy_ignore': 80},
             'epochs': 150,
             'eval_on': True,
             'lr_scheduler': {'kwargs': {'power': 0.9}, 'mode': 'poly'},
             'optimizer': {'kwargs': {'lr': 0.001,
                                      'momentum': 0.9,
                                      'weight_decay': 0.0001},
                           'type': 'SGD'},
             'unsupervised': {'TTA': False,
                              'apply_aug': 'cutmix',
                              'drop_percent': 80}}}
set random seed to 2
[2023-03-17 10:48:48,580][    INFO] # samples: 693
[2023-03-17 10:48:48,582][    INFO] # samples: 207
[2023-03-17 10:48:48,583][    INFO] Get loader Done...
[2023-03-17 10:48:49,806][    INFO] The kwargs for lr scheduler: 0.9
[2023-03-17 10:48:52,684][    INFO] [195][none] Iter [0/36750]	Data 0.00 (0.00)	Time 2.72 (2.72)	Sup 2.935 (2.935)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:48:56,209][    INFO] [195][none] Iter [10/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.928 (1.786)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:48:59,716][    INFO] [195][none] Iter [20/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.330 (0.636)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:03,227][    INFO] [195][none] Iter [30/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.693 (0.588)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:06,734][    INFO] [195][none] Iter [40/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.294 (0.400)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:10,243][    INFO] [195][none] Iter [50/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.328 (0.364)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:13,741][    INFO] [195][none] Iter [60/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.187 (0.302)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:17,250][    INFO] [195][none] Iter [70/36750]	Data 0.00 (0.00)	Time 0.36 (0.35)	Sup 0.404 (0.271)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:20,740][    INFO] [195][none] Iter [80/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.257 (0.284)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:24,244][    INFO] [195][none] Iter [90/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.169 (0.221)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:27,759][    INFO] [195][none] Iter [100/36750]	Data 0.00 (0.00)	Time 0.36 (0.35)	Sup 0.315 (0.246)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:31,287][    INFO] [195][none] Iter [110/36750]	Data 0.00 (0.00)	Time 0.36 (0.35)	Sup 0.213 (0.244)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:34,833][    INFO] [195][none] Iter [120/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.293 (0.238)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:38,395][    INFO] [195][none] Iter [130/36750]	Data 0.00 (0.00)	Time 0.36 (0.36)	Sup 0.276 (0.215)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:41,962][    INFO] [195][none] Iter [140/36750]	Data 0.00 (0.00)	Time 0.36 (0.36)	Sup 0.130 (0.218)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:45,492][    INFO] [195][none] Iter [150/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.117 (0.193)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:48,997][    INFO] [195][none] Iter [160/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.076 (0.177)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:52,500][    INFO] [195][none] Iter [170/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.125 (0.187)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:56,015][    INFO] [195][none] Iter [180/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.180 (0.180)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:49:59,522][    INFO] [195][none] Iter [190/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.226 (0.167)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:50:03,031][    INFO] [195][none] Iter [200/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.193 (0.158)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00100
[2023-03-17 10:50:06,540][    INFO] [195][none] Iter [210/36750]	Data 0.00 (0.00)	Time 0.36 (0.35)	Sup 0.281 (0.190)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00099
[2023-03-17 10:50:10,065][    INFO] [195][none] Iter [220/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.189 (0.164)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00099
[2023-03-17 10:50:13,572][    INFO] [195][none] Iter [230/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.107 (0.156)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00099
[2023-03-17 10:50:17,082][    INFO] [195][none] Iter [240/36750]	Data 0.00 (0.00)	Time 0.35 (0.35)	Sup 0.069 (0.154)	Uns 0.000 (0.000)	Con 0.000 (0.000)	LR 0.00099
[2023-03-17 10:50:18,599][    INFO] start evaluation
[2023-03-17 10:50:21,541][    INFO]  * class [0] IoU 84.62
[2023-03-17 10:50:21,541][    INFO]  * class [1] IoU 0.00
[2023-03-17 10:50:21,541][    INFO]  * class [2] IoU 48.13
[2023-03-17 10:50:21,541][    INFO]  * class [3] IoU 66.24
[2023-03-17 10:50:21,541][    INFO]  * class [4] IoU 53.68
[2023-03-17 10:50:21,541][    INFO]  * class [5] IoU 44.47
[2023-03-17 10:50:21,541][    INFO]  * class [6] IoU 0.00
[2023-03-17 10:50:21,541][    INFO]  * class [7] IoU 79.03
[2023-03-17 10:50:21,541][    INFO]  * class [8] IoU 98.63
[2023-03-17 10:50:21,541][    INFO]  * epoch 0 mIoU 52.76
[2023-03-17 10:50:24,924][    INFO] [31m * Currently, the best val result is: 52.76[0m
Traceback (most recent call last):
  File "../../../../train_semi_vit.py", line 512, in <module>
    main()
  File "../../../../train_semi_vit.py", line 174, in main
    train( model, model_teacher, optimizer,lr_scheduler,sup_loss_fn, train_loader_sup,epoch,tb_logger,logger,memobank,queue_ptrlis,queue_size,)
  File "../../../../train_semi_vit.py", line 407, in train
    loss.backward()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 23.70 GiB total capacity; 20.65 GiB already allocated; 310.56 MiB free; 22.01 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/miniconda3/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/distributed/launch.py", line 255, in main
    raise subprocess.CalledProcessError(returncode=process.returncode,
subprocess.CalledProcessError: Command '['/root/miniconda3/bin/python', '-u', '../../../../train_semi_vit.py', '--local_rank=0', '--config=config.yaml', '--seed', '2', '--port', '1255']' returned non-zero exit status 1.
